{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf35af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vespa.application import Vespa\n",
    "from dotenv import load_dotenv  \n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "# Path to your security files\n",
    "cert_path = \"/Users/shivamjogdand/Desktop/Learning/DeepAgents/Report_Generation_Git/Report_Generation/certs/public.pem\"\n",
    "key_path = \"/Users/shivamjogdand/Desktop/Learning/DeepAgents/Report_Generation_Git/Report_Generation/certs/private.pem\"\n",
    "endpoint_url = os.getenv(\"VESPA_ENDPOINT\")\n",
    "\n",
    "app = Vespa(\n",
    "    url=endpoint_url,\n",
    "    cert=cert_path,\n",
    "    key=key_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787d2676",
   "metadata": {},
   "source": [
    "# table search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625e33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Initial pages with numeric tables: [171, 178, 238, 239, 240, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279]\n",
      "[INFO] Final table pages: [171, 172, 173, 174, 175, 176, 178, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281]\n",
      "[SUCCESS] Extraction completed. Data saved to outputs/output_md_files/reconstructed_financial_tables_final_002.md\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "# ======================================================\n",
    "# 0. Models\n",
    "# ======================================================\n",
    "\n",
    "class TableResponse(BaseModel):\n",
    "    is_financial_statement: bool \n",
    "    title: str | None = None\n",
    "    raw_content: str | None = None \n",
    "\n",
    "# ======================================================\n",
    "# 1. Gemini Setup\n",
    "# ======================================================\n",
    "\n",
    "TABLE_CLASSIFICATION_PROMPT = \"\"\"\n",
    "Analyze the following document page. \n",
    "DETERMINE if it contains a primary financial statement table:\n",
    "- Income Statement / Comprehensive Income\n",
    "- Balance Sheet / Financial Position\n",
    "- Cash Flow Statement\n",
    "- Statement of Changes in Equity\n",
    "\n",
    "OUTPUT FORMAT (JSON ONLY):\n",
    "{{\n",
    "  \"is_financial_statement\": true/false,\n",
    "  \"title\": \"[Exact Statement Name from text]\"\n",
    "}}\n",
    "\n",
    "INPUT:\n",
    "Title: {page_title}\n",
    "Content: {content}\n",
    "\"\"\"\n",
    "\n",
    "gemini_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\", \n",
    "    temperature=0, \n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "structured_model = gemini_llm.with_structured_output(\n",
    "    schema=TableResponse.model_json_schema(),\n",
    "    method=\"json_schema\"\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# 2. Regex Helpers\n",
    "# ======================================================\n",
    "\n",
    "TABLE_REGEX = re.compile(r'(\\|.+\\|\\n\\|[-:\\s|]+\\|\\n(?:\\|.*\\|\\n?)*)', re.MULTILINE)\n",
    "\n",
    "def is_table_present(content: str) -> bool:\n",
    "    if not content: return False\n",
    "    return len(TABLE_REGEX.findall(content)) > 0\n",
    "\n",
    "# ======================================================\n",
    "# 3. Vespa Logic (UNCHANGED)\n",
    "# ======================================================\n",
    "\n",
    "def get_page_numbers_with_tables(hits):\n",
    "    pages = {\n",
    "        h[\"fields\"][\"page_number\"]\n",
    "        for h in hits\n",
    "        if is_table_present(h[\"fields\"].get(\"content\", \"\"))\n",
    "    }\n",
    "    print(f\"[INFO] Initial pages with numeric tables: {sorted(pages)}\")\n",
    "    return pages\n",
    "\n",
    "def fetch_specific_pages(app, tenant_id, file_id, page_list):\n",
    "    if not page_list: return []\n",
    "    pages_str = \", \".join(map(str, page_list))\n",
    "    yql = (\n",
    "        f\"select title, page_number, content \"\n",
    "        f\"from sources pefund.pefund \"\n",
    "        f\"where tenant_id contains \\\"{tenant_id}\\\" \"\n",
    "        f\"AND file_id contains \\\"{file_id}\\\" \"\n",
    "        f\"AND page_number in ({pages_str})\"\n",
    "    )\n",
    "    res = app.query(body={\"yql\": yql, \"hits\": len(page_list)})\n",
    "    return res.hits if hasattr(res, \"hits\") else res.get(\"hits\", [])\n",
    "\n",
    "def get_complete_table_sequence(app, tenant_id, file_id, query):\n",
    "    yql = (\n",
    "        f\"select title, page_number, content \"\n",
    "        f\"from sources pefund.pefund \"\n",
    "        f\"where tenant_id contains \\\"{tenant_id}\\\" \"\n",
    "        f\"AND file_id contains \\\"{file_id}\\\" \"\n",
    "        f\"AND (userQuery() or ({{targetHits:100}}nearestNeighbor(question_embeddings,q)))\"\n",
    "    )\n",
    "    res = app.query({\n",
    "        \"yql\": yql,\n",
    "        \"query\": query,\n",
    "        \"input.query(q)\": f\"embed(e5-small-v2, \\\"{query}\\\")\",\n",
    "        \"ranking\": \"default\",\n",
    "        \"hits\": 20\n",
    "    })\n",
    "    hits = res.hits if hasattr(res, \"hits\") else res.get(\"hits\", [])\n",
    "    confirmed = get_page_numbers_with_tables(hits)\n",
    "    checked = set()\n",
    "    while True:\n",
    "        candidates = {\n",
    "            n for p in confirmed\n",
    "            for n in (p - 1, p + 1)\n",
    "            if n > 0 and n not in confirmed and n not in checked\n",
    "        }\n",
    "        if not candidates: break\n",
    "        new_hits = fetch_specific_pages(app, tenant_id, file_id, list(candidates))\n",
    "        hit_map = {h[\"fields\"][\"page_number\"]: h for h in new_hits}\n",
    "        found = False\n",
    "        for p in candidates:\n",
    "            hit = hit_map.get(p)\n",
    "            if not hit:\n",
    "                checked.add(p)\n",
    "                continue\n",
    "            if is_table_present(hit[\"fields\"].get(\"content\", \"\")):\n",
    "                confirmed.add(p)\n",
    "                found = True\n",
    "            else:\n",
    "                checked.add(p)\n",
    "        if not found: break\n",
    "    final_pages = sorted(confirmed)\n",
    "    print(f\"[INFO] Final table pages: {final_pages}\")\n",
    "    final_hits = fetch_specific_pages(app, tenant_id, file_id, final_pages)\n",
    "    final_hits.sort(key=lambda h: h[\"fields\"][\"page_number\"])\n",
    "    return final_hits\n",
    "\n",
    "# ======================================================\n",
    "# 4. Parallel Processing\n",
    "# ======================================================\n",
    "\n",
    "def process_single_hit(args):\n",
    "    idx, hit = args\n",
    "    content = hit[\"fields\"].get(\"content\", \"\")\n",
    "    \n",
    "    result = structured_model.invoke(\n",
    "        TABLE_CLASSIFICATION_PROMPT.format(\n",
    "            page_title=hit[\"fields\"].get(\"title\", \"\"),\n",
    "            content=content\n",
    "        )\n",
    "    )\n",
    "\n",
    "    parsed = TableResponse.model_validate(result)\n",
    "    parsed.raw_content = content \n",
    "\n",
    "    if not parsed.is_financial_statement:\n",
    "        return idx, None\n",
    "\n",
    "    return idx, parsed\n",
    "\n",
    "# ======================================================\n",
    "# 6. Execute & Write to File\n",
    "# ======================================================\n",
    "\n",
    "TENANT_ID = \"0f7a4b5f-a137-4a71-b518-1a04ba239b61\"\n",
    "FILE_ID = \"9de6cf15-b315-4270-92c0-aa648b818949\"\n",
    "QUERY = \"consolidated financial statements\"\n",
    "OUTPUT_FILE = \"outputs/output_md_files/reconstructed_financial_tables_final_002.md\"\n",
    "\n",
    "hits = get_complete_table_sequence(app, TENANT_ID, FILE_ID, QUERY)\n",
    "results = [None] * len(hits)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as pool:\n",
    "    for idx, response in pool.map(process_single_hit, enumerate(hits)):\n",
    "        results[idx] = response\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    for r in results:\n",
    "        if r and r.raw_content:\n",
    "            # Title handling: Ensure ### prefix\n",
    "            if r.title:\n",
    "                clean_title = r.title.lstrip(\"# \").strip()\n",
    "                f.write(f\"### {clean_title}\\n\\n\")\n",
    "            \n",
    "            f.write(r.raw_content + \"\\n\\n\")\n",
    "            f.write(\"---\\n\\n\")\n",
    "\n",
    "print(f\"[SUCCESS] Extraction completed. Data saved to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a701e",
   "metadata": {},
   "source": [
    "# Question Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b2cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing 6 financial sections...\n",
      "[SUCCESS] Generated questions for: CONSOLIDATED STATEMENT OF FINANCIAL POSITION\n",
      "[SUCCESS] Generated questions for: CONSOLIDATED STATEMENT OF INCOME\n",
      "[SUCCESS] Generated questions for: CONSOLIDATED STATEMENT OF COMPREHENSIVE INCOME\n",
      "[SUCCESS] Generated questions for: CONSOLIDATED STATEMENT OF CHANGES IN EQUITY\n",
      "[SUCCESS] Generated questions for: CONSOLIDATED STATEMENT OF CASH FLOWS\n",
      "[SUCCESS] Generated questions for: CONSOLIDATED STATEMENT OF CASH FLOWS (CONTINUED)\n",
      "[FINISH] All questions saved to outputs/output_md_files/pe_due_diligence_questions_pro.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# ======================================================\n",
    "# 1. Setup & Configuration\n",
    "# ======================================================\n",
    "\n",
    "# Define the headers to split on (matches our ### Title from previous step)\n",
    "headers_to_split_on = [\n",
    "    (\"###\", \"Header_Title\"),\n",
    "]\n",
    "\n",
    "# Initialize the Splitter\n",
    "header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "# Initialize Gemini for Question Generation\n",
    "gemini_pe_analyst = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-pro\", \n",
    "    temperature=0.7, \n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "class QuestionList(BaseModel):\n",
    "    questions: List[str] = Field(description=\"List of due diligence questions\")\n",
    "\n",
    "# Structured output for clean parsing\n",
    "structured_qa_model = gemini_pe_analyst.with_structured_output(QuestionList)\n",
    "\n",
    "# ======================================================\n",
    "# 2. Updated Managing Director PE Prompt\n",
    "# ======================================================\n",
    "\n",
    "PE_DUE_DILIGENCE_PROMPT = \"\"\"\n",
    "[SYSTEM OPERATING DIRECTIVE: ACT AS A SENIOR MANAGING DIRECTOR & HEAD OF DUE DILIGENCE]\n",
    "You are conducting a final Investment Committee (IC) review for a multi-billion dollar acquisition. You are skeptical, intellectually aggressive, and focused on protecting Limited Partner (LP) capital.\n",
    "\n",
    "**TARGET SEGMENT:** {header_title}\n",
    "**FINANCIAL DATA SOURCE:** ---\n",
    "{chunk_content}\n",
    "---\n",
    "\n",
    "**CORE OBJECTIVE:**\n",
    "Generate 5-7 \"Investment Committee Grade\" questions. Your goal is to dismantle the management's narrative and uncover the \"Truth behind the GAAP/IFRS numbers.\"\n",
    "\n",
    "**STRATEGIC QUESTIONING PILLARS:**\n",
    "1. **Quality of Earnings (QoE) & Accrual Integrity:** Identify where non-cash items or \"one-time\" adjustments might be masking a decline in core operational health. Look at Note 34 (Discontinued Operations) or Note 31 (Zakat/Tax) to see if tax releases are padding the bottom line.\n",
    "2. **Capital Intensity & Asset Obsolescence:** If looking at the Statement of Financial Position, cross-reference PP&E (112B) against Depreciation (11.4B). Ask if the current \"Repairs and Maintenance\" (4.2B) is sufficient to maintain competitive parity or if there is a massive CAPEX \"bow wave\" coming.\n",
    "3. **Liquidity & Structural Subordination:** Analyze the SAR 45.3B in Current Liabilities against the SAR 30.5B Cash position. Question the reliance on \"Short-term investments\" and \"Trade payables\" as a primary financing vehicle.\n",
    "4. **Macro-Economic Sensitivity:** Specifically target the SAR/USD peg. Ask about the \"Exchange difference on translation\" (which showed a 1.2B loss in 2024) and how a potential de-pegging or regional instability would impact the LTM debt-to-equity ratio.\n",
    "5. **Entity-Level Complexity:** Use the data from \"Material Associates\" or \"Non-Controlling Interests\" to ask about structural leakage. (e.g., \"Why are we seeing high dividend outflows to NCI (2.6B) while the Parent's Retained Earnings are under pressure?\").\n",
    "\n",
    "**MANDATORY CONSTRAINTS:**\n",
    "- NO generic questions (e.g., \"Why did revenue change?\").\n",
    "- USE advanced financial metrics: ROIC, Free Cash Flow Conversion, Working Capital Intensity, and LTM Bridge Analysis.\n",
    "- DO NOT be limited by the provided text; if the text suggests a risk (like a discontinued operation), ask about the strategic fallout even if the answer isn't in the chunk.\n",
    "\"\"\"\n",
    "\n",
    "# ======================================================\n",
    "# 3. Processing & File Saving\n",
    "# ======================================================\n",
    "\n",
    "INPUT_FILE = \"outputs/output_md_files/reconstructed_financial_tables_final_002.md\"\n",
    "QUESTIONS_OUTPUT_FILE = \"outputs/output_md_files/pe_due_diligence_questions_pro.md\"\n",
    "\n",
    "def generate_pe_questions():\n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        print(f\"[ERROR] Input file {INPUT_FILE} not found.\")\n",
    "        return\n",
    "\n",
    "    with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        md_content = f.read()\n",
    "\n",
    "    # Split the document based on the ### Headers\n",
    "    sections = header_splitter.split_text(md_content)\n",
    "    \n",
    "    all_qa_content = []\n",
    "\n",
    "    print(f\"[INFO] Processing {len(sections)} financial sections...\")\n",
    "\n",
    "    for section in sections:\n",
    "        header = section.metadata.get(\"Header_Title\", \"Financial Statement Section\")\n",
    "        content = section.page_content\n",
    "\n",
    "        # Generate Questions via Gemini using the MD Prompt\n",
    "        formatted_prompt = PE_DUE_DILIGENCE_PROMPT.format(\n",
    "            header_title=header,\n",
    "            chunk_content=content\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            response = structured_qa_model.invoke(formatted_prompt)\n",
    "            \n",
    "            # Format for the output file\n",
    "            section_output = f\"## Due Diligence Questions: {header}\\n\\n\"\n",
    "            for i, q in enumerate(response.questions, 1):\n",
    "                section_output += f\"{i}. {q}\\n\"\n",
    "            section_output += \"\\n---\\n\\n\"\n",
    "            \n",
    "            all_qa_content.append(section_output)\n",
    "            print(f\"[SUCCESS] Generated questions for: {header}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed for {header}: {e}\")\n",
    "\n",
    "    # Save to final file\n",
    "    with open(QUESTIONS_OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(all_qa_content)\n",
    "\n",
    "    print(f\"[FINISH] All questions saved to {QUESTIONS_OUTPUT_FILE}\")\n",
    "\n",
    "generate_pe_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb80cd50",
   "metadata": {},
   "source": [
    "# /questionnaire endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbab0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 1 financial sections. Starting sequential processing...\n",
      "\n",
      "============================================================\n",
      "SECTION: CONSOLIDATED STATEMENT OF FINANCIAL POSITION\n",
      "============================================================\n",
      "[LLM] Generated 5 high-stakes questions.\n",
      "\n",
      "[QUESTION 1]: The balance sheet reflects a significant reduction in 'Assets held for sale' (from SAR 15.4B to SAR 3.6B) and associated liabilities, alongside a sharp decline in 'Zakat payable' (from SAR 1.4B to SAR 0.1B) and 'Current Provisions' (from SAR 1.1B to SAR 0.1B). What is the LTM Free Cash Flow Conversion adjusted for the impact of these asset disposals and potential one-time P&L benefits from provision/Zakat releases? Specifically, provide a bridge showing how these non-recurring items influenced reported operating cash flow and the material increase in 'Other current assets and receivables' (SAR 5B+).\n",
      "[API RESPONSE]: SUCCESS - Request ID: 8fa6a014-f004-47bb-bb75-805e61a615cb\n",
      "\n",
      "[QUESTION 2]: Total non-current assets, particularly Property, Plant and Equipment (Note 7) and Investments in associates and joint ventures (Note 10), have decreased by SAR 7.1 billion and SAR 5.8 billion respectively, in 2024. Considering the context of high depreciation (SAR 11.4B) and potentially inadequate 'Repairs and Maintenance' (SAR 4.2B) as provided, what is the current ROIC trend for the core operating assets, excluding divested entities? Provide an LTM bridge analysis of CAPEX, depreciation, and asset disposals to demonstrate whether the remaining asset base is being sufficiently reinvested in to sustain future earnings or if we are seeing asset stripping.\n",
      "[API RESPONSE]: SUCCESS - Request ID: 164d6389-d61e-429b-b63d-32b06b577861\n",
      "\n",
      "[QUESTION 3]: Despite a seemingly healthy working capital position of SAR 46 billion, total current liabilities stand at SAR 45.3 billion, which is significantly higher than the SAR 30.5 billion cash on hand. Explain the company's detailed liquidity management strategy. Specifically, quantify the working capital intensity and provide a granular breakdown of how the SAR 19.6 billion 'Other current liabilities' are financed. Is the company relying on extended payment terms for trade payables or other forms of short-term financing to cover operational gaps, which could signal structural subordination for new debt holders?\n",
      "[API RESPONSE]: SUCCESS - Request ID: 263b9527-226c-4431-b595-35a6d8681433\n",
      "\n",
      "[QUESTION 4]: The prompt indicates a SAR 1.2 billion 'Exchange difference on translation' loss in 2024, signaling significant foreign currency exposure, likely exacerbated by the SAR/USD peg. With SAR 28.1 billion in total debt and SAR 156.8 billion in equity attributable to parent holders, what is the company's sensitivity analysis to a hypothetical 5% and 10% revaluation or de-pegging of the Saudi Riyal? Provide a stress-tested LTM debt-to-equity ratio and detail the currency hedging strategy for foreign-denominated assets and liabilities, especially considering the substantial investments in associates and joint ventures.\n",
      "[API RESPONSE]: SUCCESS - Request ID: c66a6783-16e8-49a9-903d-c5122e60c77f\n",
      "\n",
      "[QUESTION 5]: Retained earnings attributable to equity holders of the Parent have significantly declined by SAR 8.1 billion, while 'Non-controlling interests' (Note 21) have also decreased. This suggests either poor operating performance, substantial distributions, or significant impairments within controlled entities. Can management provide a detailed breakdown of the key drivers for the decline in parent-level retained earnings? Specifically, how much of this decline is attributable to operational losses versus dividends paid to non-controlling interests (e.g., the reported SAR 2.6B outflow), and what is the strategic rationale for the current ownership structure, given potential structural leakage impacting the Parent's ability to retain capital for reinvestment?\n",
      "[API RESPONSE]: SUCCESS - Request ID: c0947b34-1658-4948-85a6-3e5e76f02206\n",
      "\n",
      "[SUCCESS] Full report saved to outputs/output_md_files/pe_due_diligence_results.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import httpx\n",
    "import json\n",
    "import time\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# ======================================================\n",
    "# 1. Configuration & Persona Setup\n",
    "# ======================================================\n",
    "\n",
    "# Endpoint Configuration\n",
    "API_URL = \"http://localhost:8000/api/questionnaire\" \n",
    "TENANT_ID = \"d90887dc-391e-430c-921f-6d3f86bf8a81\" \n",
    "INPUT_FILE = \"outputs/output_md_files/sample_table.md\"\n",
    "JSON_OUTPUT_FILE = \"outputs/output_md_files/pe_due_diligence_results.json\"\n",
    "\n",
    "# Model Setup\n",
    "gemini_pe_analyst = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    temperature=0.7, \n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "class QuestionList(BaseModel):\n",
    "    questions: List[str] = Field(description=\"List of due diligence questions\")\n",
    "\n",
    "structured_qa_model = gemini_pe_analyst.with_structured_output(QuestionList)\n",
    "\n",
    "# ======================================================\n",
    "# 2. Robust PE Managing Director Prompt\n",
    "# ======================================================\n",
    "\n",
    "PE_DUE_DILIGENCE_PROMPT = \"\"\"\n",
    "[SYSTEM OPERATING DIRECTIVE: ACT AS A SENIOR MANAGING DIRECTOR & HEAD OF DUE DILIGENCE]\n",
    "You are conducting a final Investment Committee (IC) review for a multi-billion dollar acquisition. You are skeptical, intellectually aggressive, and focused on protecting Limited Partner (LP) capital.\n",
    "\n",
    "**TARGET SEGMENT:** {header_title}\n",
    "**FINANCIAL DATA SOURCE:** ---\n",
    "{chunk_content}\n",
    "---\n",
    "\n",
    "**CORE OBJECTIVE:**\n",
    "Generate 5-7 \"Investment Committee Grade\" questions. Your goal is to dismantle the management's narrative and uncover the \"Truth behind the GAAP/IFRS numbers.\"\n",
    "\n",
    "**STRATEGIC QUESTIONING PILLARS:**\n",
    "1. **Quality of Earnings (QoE) & Accrual Integrity:** Identify where non-cash items or \"one-time\" adjustments might be masking a decline in core operational health. Look at Note 34 (Discontinued Operations) or Note 31 (Zakat/Tax) to see if tax releases are padding the bottom line.\n",
    "2. **Capital Intensity & Asset Obsolescence:** If looking at the Statement of Financial Position, cross-reference PP&E (112B) against Depreciation (11.4B). Ask if the current \"Repairs and Maintenance\" (4.2B) is sufficient to maintain competitive parity or if there is a massive CAPEX \"bow wave\" coming.\n",
    "3. **Liquidity & Structural Subordination:** Analyze the SAR 45.3B in Current Liabilities against the SAR 30.5B Cash position. Question the reliance on \"Short-term investments\" and \"Trade payables\" as a primary financing vehicle.\n",
    "4. **Macro-Economic Sensitivity:** Specifically target the SAR/USD peg. Ask about the \"Exchange difference on translation\" (which showed a 1.2B loss in 2024) and how a potential de-pegging or regional instability would impact the LTM debt-to-equity ratio.\n",
    "5. **Entity-Level Complexity:** Use the data from \"Material Associates\" or \"Non-Controlling Interests\" to ask about structural leakage. (e.g., \"Why are we seeing high dividend outflows to NCI (2.6B) while the Parent's Retained Earnings are under pressure?\").\n",
    "\n",
    "**MANDATORY CONSTRAINTS:**\n",
    "- NO generic questions (e.g., \"Why did revenue change?\").\n",
    "- USE advanced financial metrics: ROIC, Free Cash Flow Conversion, Working Capital Intensity, and LTM Bridge Analysis.\n",
    "- DO NOT be limited by the provided text; if the text suggests a risk (like a discontinued operation), ask about the strategic fallout even if the answer isn't in the chunk.\n",
    "\"\"\"\n",
    "\n",
    "# ======================================================\n",
    "# 3. Execution Engine\n",
    "# ======================================================\n",
    "\n",
    "def run_sequential_pipeline():\n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        print(f\"Error: {INPUT_FILE} not found.\")\n",
    "        return\n",
    "\n",
    "    # 1. Read and Split Content\n",
    "    with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        md_content = f.read()\n",
    "\n",
    "    headers_to_split_on = [(\"###\", \"Header_Title\")]\n",
    "    splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "    sections = splitter.split_text(md_content)\n",
    "\n",
    "    final_report_data = []\n",
    "    print(f\"[INFO] Found {len(sections)} financial sections. Starting sequential processing...\")\n",
    "\n",
    "    # 2. Process each section one by one\n",
    "    for section in sections:\n",
    "        header = section.metadata.get(\"Header_Title\", \"Financial Section\")\n",
    "        print(f\"\\n{'='*60}\\nSECTION: {header}\\n{'='*60}\")\n",
    "\n",
    "        section_results = {\n",
    "            \"section_title\": header,\n",
    "            \"timestamp\": time.ctime(),\n",
    "            \"due_diligence_inquiries\": []\n",
    "        }\n",
    "\n",
    "        # Generate Questions\n",
    "        formatted_prompt = PE_DUE_DILIGENCE_PROMPT.format(\n",
    "            header_title=header,\n",
    "            chunk_content=section.page_content\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = structured_qa_model.invoke(formatted_prompt)\n",
    "            questions = response.questions\n",
    "            print(f\"[LLM] Generated {len(questions)} high-stakes questions.\")\n",
    "        except Exception as e:\n",
    "            print(f\"[LLM ERROR] Failed to generate questions for {header}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 3. Hit API for each question sequentially\n",
    "        for i, q in enumerate(questions, 1):\n",
    "            print(f\"\\n[QUESTION {i}]: {q}\")\n",
    "\n",
    "            payload = {\n",
    "                \"query\": q,\n",
    "                \"description\": f\"Senior PE Due Diligence analysis for {header}. Strategic risk evaluation.\",\n",
    "                \"request_id\": str(uuid.uuid4()),\n",
    "                \"web_search\": False,\n",
    "                \"response_type\": \"informative\",\n",
    "                \"tenant_id\": TENANT_ID\n",
    "            }\n",
    "\n",
    "            with httpx.Client(timeout=180.0) as client:\n",
    "                try:\n",
    "                    api_resp = client.post(API_URL, json=payload)\n",
    "                    if api_resp.status_code == 200:\n",
    "                        full_result = api_resp.json()\n",
    "                        print(f\"[API RESPONSE]: SUCCESS - Request ID: {payload['request_id']}\")\n",
    "                        \n",
    "                        # Properly capture complete JSON response for each inquiry\n",
    "                        section_results[\"due_diligence_inquiries\"].append({\n",
    "                            \"question\": q,\n",
    "                            \"api_response\": full_result\n",
    "                        })\n",
    "                    else:\n",
    "                        print(f\"[API ERROR]: Status {api_resp.status_code} - {api_resp.text}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"[API CONNECTION ERROR]: {e}\")\n",
    "\n",
    "        final_report_data.append(section_results)\n",
    "\n",
    "    # 4. Save entire object as properly formatted JSON\n",
    "    with open(JSON_OUTPUT_FILE, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(final_report_data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\n[SUCCESS] Full report saved to {JSON_OUTPUT_FILE}\")\n",
    "\n",
    "\n",
    "run_sequential_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18cba45",
   "metadata": {},
   "source": [
    "# /chat endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0aa8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 1 financial sections. Starting sequential Chat processing...\n",
      "\n",
      "============================================================\n",
      "SECTION: CONSOLIDATED STATEMENT OF FINANCIAL POSITION\n",
      "============================================================\n",
      "[LLM] Generated 5 high-stakes questions.\n",
      "\n",
      "[QUESTION 1]: The significant decrease in 'Assets held for sale' from SAR 15.4 billion to SAR 3.6 billion, coupled with the corresponding elimination of 'Liabilities directly associated with assets held for sale' (SAR 5.7 billion), suggests substantial divestitures. What was the net gain or loss on these disposals, how much of it was recognized as 'one-off' or non-operating income, and what is the pro-forma Quality of Earnings, Free Cash Flow Conversion, and ROIC of the *retained* core business, isolating the impact of these asset sales?\n",
      "[API RESPONSE]: SUCCESS - Session ID: 71a45270-34e3-4dae-bbd0-28cc2b90b2c6\n",
      "\n",
      "[QUESTION 2]: Net Property, Plant & Equipment and Intangible Assets have both shown declines. What is the company's actual maintenance CAPEX relative to depreciation and amortization over the last three years, and how does this compare to industry benchmarks for similar capital-intensive operations? Can management demonstrate that current reinvestment levels are sufficient to prevent operational obsolescence and sustain competitive advantage, particularly concerning the impact on future ROIC and productive capacity?\n",
      "[API RESPONSE]: SUCCESS - Session ID: 71a45270-34e3-4dae-bbd0-28cc2b90b2c6\n",
      "\n",
      "[QUESTION 3]: 'Other current assets and receivables' have surged from SAR 5.3 billion to SAR 10.3 billion, while 'Short-term investments' have decreased, and cash positions have slightly declined. What is the granular composition, aging, and collectability risk profile of this significantly expanded 'Other current assets and receivables' balance? How does this increase in Working Capital Intensity impact the company's Free Cash Flow generation, and what provisions are in place to mitigate potential liquidity shocks from slower collections?\n",
      "[API RESPONSE]: SUCCESS - Session ID: 71a45270-34e3-4dae-bbd0-28cc2b90b2c6\n",
      "\n",
      "[QUESTION 4]: The negative and deteriorating 'Other reserves' (from -SAR 1.58 billion to -SAR 4.11 billion) often indicate significant foreign currency translation losses or revaluation deficits. What is the geographic breakdown of the underlying assets and liabilities contributing to this deficit, particularly within 'Investments in associates and joint ventures' and 'Derivative financial instruments'? How is the company positioned to mitigate further macro-economic volatility, including potential interest rate increases and currency devaluations in key operating markets, and what is the sensitivity of our consolidated equity and future cash flows to these risks?\n",
      "[API RESPONSE]: SUCCESS - Session ID: 71a45270-34e3-4dae-bbd0-28cc2b90b2c6\n",
      "\n",
      "[QUESTION 5]: Non-controlling interests remain substantial at SAR 27 billion, representing nearly 15% of total equity, and 'Investments in associates and joint ventures' have declined materially. What is the specific contribution of these non-100% owned entities to the consolidated entity's EBITDA and Free Cash Flow, and what are the contractual and practical mechanisms for upstreaming cash to the parent? Critically, what is the effective \"leakage\" of cash flow to non-controlling interests and how does this impact our calculation of Free Cash Flow to Equity (FCFE) and overall value creation for our LPs, especially considering any structural subordination?\n",
      "[API RESPONSE]: SUCCESS - Session ID: 71a45270-34e3-4dae-bbd0-28cc2b90b2c6\n",
      "\n",
      "[SUCCESS] Full Chat report saved to outputs/output_md_files/pe_due_diligence_results_chat.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import httpx\n",
    "import json\n",
    "import time\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# ======================================================\n",
    "# 1. Configuration & Persona Setup\n",
    "# ======================================================\n",
    "\n",
    "# Endpoint Configuration\n",
    "API_URL = \"http://localhost:8000/api/chat\" \n",
    "TENANT_ID = \"0f7a4b5f-a137-4a71-b518-1a04ba239b61\" # Updated to match your chat payload\n",
    "INPUT_FILE = \"outputs/output_md_files/sample_table.md\"\n",
    "JSON_OUTPUT_FILE = \"outputs/output_md_files/pe_due_diligence_results_chat.json\"\n",
    "\n",
    "# Model Setup\n",
    "gemini_pe_analyst = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    temperature=0.7, \n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "class QuestionList(BaseModel):\n",
    "    questions: List[str] = Field(description=\"List of due diligence questions\")\n",
    "\n",
    "structured_qa_model = gemini_pe_analyst.with_structured_output(QuestionList)\n",
    "\n",
    "# ======================================================\n",
    "# 2. Robust PE Managing Director Prompt\n",
    "# ======================================================\n",
    "\n",
    "PE_DUE_DILIGENCE_PROMPT = \"\"\"\n",
    "[SYSTEM OPERATING DIRECTIVE: ACT AS A SENIOR MANAGING DIRECTOR & HEAD OF DUE DILIGENCE]\n",
    "You are conducting a final Investment Committee (IC) review for a multi-billion dollar acquisition. You are skeptical, intellectually aggressive, and focused on protecting Limited Partner (LP) capital.\n",
    "\n",
    "**TARGET SEGMENT:** {header_title}\n",
    "**FINANCIAL DATA SOURCE:** ---\n",
    "{chunk_content}\n",
    "---\n",
    "\n",
    "**CORE OBJECTIVE:**\n",
    "Generate 5-7 \"Investment Committee Grade\" questions. Your goal is to dismantle the management's narrative and uncover the \"Truth behind the GAAP/IFRS numbers.\"\n",
    "\n",
    "**STRATEGIC QUESTIONING PILLARS:**\n",
    "1. **Quality of Earnings (QoE) & Accrual Integrity:** Identify where non-cash items or \"one-time\" adjustments might be masking a decline in core operational health.\n",
    "2. **Capital Intensity & Asset Obsolescence:** Question if maintenance CAPEX is sufficient to avoid operational obsolescence.\n",
    "3. **Liquidity & Structural Subordination:** Analyze Current Liabilities against Cash positions.\n",
    "4. **Macro-Economic Sensitivity:** Specifically target the SAR/USD peg and translation losses.\n",
    "5. **Entity-Level Complexity:** Look at Material Associates or Non-Controlling Interests for structural leakage.\n",
    "\n",
    "**MANDATORY CONSTRAINTS:**\n",
    "- NO generic questions.\n",
    "- USE advanced financial metrics: ROIC, Free Cash Flow Conversion, Working Capital Intensity.\n",
    "- DO NOT be limited by the provided text; ask about strategic fallout and hidden risks.\n",
    "\"\"\"\n",
    "\n",
    "# ======================================================\n",
    "# 3. Execution Engine\n",
    "# ======================================================\n",
    "\n",
    "def run_chat_sequential_pipeline():\n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        print(f\"Error: {INPUT_FILE} not found.\")\n",
    "        return\n",
    "\n",
    "    # 1. Read and Split Content\n",
    "    with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        md_content = f.read()\n",
    "\n",
    "    headers_to_split_on = [(\"###\", \"Header_Title\")]\n",
    "    splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "    sections = splitter.split_text(md_content)\n",
    "\n",
    "    final_report_data = []\n",
    "    session_id = str(uuid.uuid4()) # Persistent session for this entire run\n",
    "    print(f\"[INFO] Found {len(sections)} financial sections. Starting sequential Chat processing...\")\n",
    "\n",
    "    # 2. Process each section one by one\n",
    "    for section in sections:\n",
    "        header = section.metadata.get(\"Header_Title\", \"Financial Section\")\n",
    "        print(f\"\\n{'='*60}\\nSECTION: {header}\\n{'='*60}\")\n",
    "\n",
    "        section_results = {\n",
    "            \"section_title\": header,\n",
    "            \"timestamp\": time.ctime(),\n",
    "            \"chat_inquiries\": []\n",
    "        }\n",
    "\n",
    "        # Generate Questions\n",
    "        formatted_prompt = PE_DUE_DILIGENCE_PROMPT.format(\n",
    "            header_title=header,\n",
    "            chunk_content=section.page_content\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = structured_qa_model.invoke(formatted_prompt)\n",
    "            questions = response.questions\n",
    "            print(f\"[LLM] Generated {len(questions)} high-stakes questions.\")\n",
    "        except Exception as e:\n",
    "            print(f\"[LLM ERROR] Failed to generate questions for {header}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 3. Hit /chat API for each question sequentially\n",
    "        for i, q in enumerate(questions, 1):\n",
    "            print(f\"\\n[QUESTION {i}]: {q}\")\n",
    "\n",
    "            # Construct Chat Payload\n",
    "            payload = {\n",
    "                \"query\": q,\n",
    "                \"session_id\": session_id,\n",
    "                \"message_id\": str(i),\n",
    "                \"web_search\": False,\n",
    "                \"conversations\": [],\n",
    "                \"tenant_ids\": [TENANT_ID]\n",
    "            }\n",
    "\n",
    "            with httpx.Client(timeout=180.0) as client:\n",
    "                try:\n",
    "                    api_resp = client.post(API_URL, json=payload)\n",
    "                    if api_resp.status_code == 200:\n",
    "                        full_result = api_resp.json()\n",
    "                        print(f\"[API RESPONSE]: SUCCESS - Session ID: {session_id}\")\n",
    "                        \n",
    "                        # Properly capture complete JSON response for each inquiry\n",
    "                        section_results[\"chat_inquiries\"].append({\n",
    "                            \"question\": q,\n",
    "                            \"api_response\": full_result\n",
    "                        })\n",
    "                    else:\n",
    "                        print(f\"[API ERROR]: Status {api_resp.status_code} - {api_resp.text}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"[API CONNECTION ERROR]: {e}\")\n",
    "\n",
    "        final_report_data.append(section_results)\n",
    "\n",
    "    # 4. Save entire object as properly formatted JSON\n",
    "    with open(JSON_OUTPUT_FILE, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(final_report_data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\n[SUCCESS] Full Chat report saved to {JSON_OUTPUT_FILE}\")\n",
    "\n",
    "\n",
    "run_chat_sequential_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fe0504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
